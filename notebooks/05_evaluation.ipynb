# 05 Model Evaluation - Credit Risk
import pandas as pd
import numpy as np
import joblib
import shap
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score

# Load feature engineered data
df = pd.read_csv('data/processed/application_train_fe.csv')
y = df['TARGET']
X = df.drop('TARGET', axis=1)

# Load final trained model
model = joblib.load('models/lightgbm_final.pkl')

# Predictions
preds_proba = model.predict_proba(X)[:,1]
preds = (preds_proba > 0.5).astype(int)

# Metrics
auc = roc_auc_score(y, preds_proba)
precision = precision_score(y, preds)
recall = recall_score(y, preds)
f1 = f1_score(y, preds)

# SHAP Analysis
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X)

# Plot feature importance
plt.figure(figsize=(10,8))
shap.summary_plot(shap_values, X, plot_type="bar")
plt.savefig('shap_feature_importance.png')

# Save key evaluation metrics
metrics_df = pd.DataFrame({
    'AUC':[auc],
    'Precision':[precision],
    'Recall':[recall],
    'F1':[f1]
})
metrics_df.to_csv('models/evaluation_metrics.csv', index=False)

auc, precision, recall, f1